// this file copied and modified from the GATK repository: https://github.com/broadinstitute/gatk
// 

//Note: this section 'buildscript` is only for the dependencies of the buildscript itself.
// See the second 'repositories' section below for the actual dependencies of GATK itself
buildscript {
    repositories {
        mavenCentral()
        jcenter() // for shadow plugin
    }
}

plugins {
    id "java"           // set up default java compile and test tasks
    id "application"    // provides installDist
    id "com.github.johnrengelman.shadow" version "2.0.4"    //used to build the shadow and sparkJars
    id 'com.palantir.git-version' version '0.5.1' //version helper
}


import com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar
import javax.tools.ToolProvider

apply plugin: 'java'

repositories {
    mavenCentral()
    jcenter()

    maven {
        url "https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/" //for htsjdk snapshots
    }

    mavenLocal()
}

//Note: the test suite must use the same defaults. If you change system properties in this list you must also update the one in the test task
applicationDefaultJvmArgs = ["-Dsamjdk.use_async_io_read_samtools=false","-Dsamjdk.use_async_io_write_samtools=true", "-Dsamjdk.use_async_io_write_tribble=false", "-Dsamjdk.compression_level=2"]


mainClassName = "org.broadinstitute.quartetibdanalysis.Main"

final requiredJavaVersion = "8"
final htsjdkVersion = System.getProperty('htsjdk.version','2.18.2')
final picardVersion = System.getProperty('picard.version','2.18.25')
final barclayVersion = System.getProperty('barclay.version','2.1.0')
final gatkVersion = System.getProperty('gatk.version','4.1.1.0')
final testNGVersion = '6.11'
// Using the shaded version to avoid conflicts between its protobuf dependency
// and that of Hadoop/Spark (either the one we reference explicitly, or the one
// provided by dataproc).
final googleCloudNioDependency = 'com.google.cloud:google-cloud-nio:0.81.0-alpha:shaded'

final docBuildDir = "$buildDir/docs"
logger.info(docBuildDir)

configurations.all {
    resolutionStrategy {
        // the snapshot folder contains a dev version of guava, we don't want to use that.
        force 'com.google.guava:guava:18.0'
        // force the htsjdk version so we don't get a different one transitively
        force 'com.github.samtools:htsjdk:' + htsjdkVersion
        // later versions explode Hadoop
        force 'com.google.protobuf:protobuf-java:3.0.0-beta-1'
        // force testng dependency so we don't pick up a different version via GenomicsDB
        //force 'org.testng:testng:' + testNGVersion
        force 'org.broadinstitute:barclay:' + barclayVersion

        // make sure we don't pick up an incorrect version of the GATK variant of the google-nio library
        // via Picard, etc.
        force googleCloudNioDependency
    }
    all*.exclude group: 'org.slf4j', module: 'slf4j-jdk14' //exclude this to prevent slf4j complaining about to many slf4j bindings
    all*.exclude group: 'com.google.guava', module: 'guava-jdk5'
    all*.exclude group: 'junit', module: 'junit'
}

tasks.withType(JavaCompile) {
    options.compilerArgs = ['-proc:none', '-Xlint:all', '-Werror', '-Xdiags:verbose']
}

sourceSets {
    testUtils
}

// Get the jdk files we need to run javaDoc. We need to use these during compile, testCompile,
// test execution, and gatkDoc generation, but we don't want them as part of the runtime
// classpath and we don't want to redistribute them in the uber jar.
//final javadocJDKFiles = files(((URLClassLoader) ToolProvider.getSystemToolClassLoader()).getURLs())

configurations {
    testUtilsCompile.extendsFrom compile
    testUtilsRuntime.extendsFrom runtime

    testCompile.extendsFrom testUtilsCompile
    testRuntime.extendsFrom testUtilsRuntime

    externalSourceConfiguration {
        // External sources we need for doc and tab completion generation tasks (i.e., Picard sources)
        transitive false
    }
}

dependencies {
    compile files('lib/SVToolkit.jar')
    compile 'org.broadinstitute:gatk:' + gatkVersion
    // javadoc utilities; compile/test only to prevent redistribution of sdk jars
    //compileOnly(javadocJDKFiles)
    //testCompile(javadocJDKFiles)

    compile 'org.broadinstitute:barclay:' + barclayVersion

    compile 'com.github.broadinstitute:picard:' + picardVersion
    externalSourceConfiguration 'com.github.broadinstitute:picard:' + picardVersion + ':sources'
    compile 'com.opencsv:opencsv:3.4'
    compile 'com.google.guava:guava:18.0'
    compile 'com.github.samtools:htsjdk:'+ htsjdkVersion
    compile googleCloudNioDependency

    compile "gov.nist.math.jama:gov.nist.math.jama:1.1.1"

    // this comes built-in when running on Google Dataproc, but the library
    // allows us to read from GCS also when testing locally (or on non-Dataproc clusters,
    // should we want to)
    compile 'com.google.cloud.bigdataoss:gcs-connector:1.6.3-hadoop2'

    compile 'org.apache.logging.log4j:log4j-api:2.3'
    compile 'org.apache.logging.log4j:log4j-core:2.3'
    // include the apache commons-logging bridge that matches the log4j version we use so
    // messages that originate with dependencies that use commons-logging (such as jexl)
    // are routed to log4j
    compile 'org.apache.logging.log4j:log4j-jcl:2.3'

    compile 'org.apache.commons:commons-lang3:3.5'
    compile 'org.apache.commons:commons-math3:3.5'
    compile 'org.apache.commons:commons-collections4:4.1'
    compile 'org.apache.commons:commons-vfs2:2.0'
    compile 'commons-io:commons-io:2.5'
    compile 'org.reflections:reflections:0.9.10'

    compile 'it.unimi.dsi:fastutil:7.0.6'

    compile 'org.broadinstitute:hdf5-java-bindings:1.1.0-hdf5_2.11.0'
    compile 'org.broadinstitute:gatk-native-bindings:1.0.0'

    compile 'org.ojalgo:ojalgo:44.0.0'
    compile ('org.ojalgo:ojalgo-commons-math3:1.0.0') {
        exclude group: 'org.apache.commons'
    }
    
    // Required for SV Discovery machine learning
    compile group: 'biz.k11i', name: 'xgboost-predictor', version: '0.3.0'

    testUtilsCompile sourceSets.main.output
    testUtilsCompile 'org.testng:testng:' + testNGVersion

    testCompile sourceSets.testUtils.output
    testUtilsCompile 'org.testng:testng:' + testNGVersion

    testCompile "org.mockito:mockito-core:2.10.0"
    testCompile "com.google.jimfs:jimfs:1.1"
}

//add gatk launcher script to the jar as a resource
processResources {
    from("quartetibdanalysis")
}

sourceCompatibility = 1.8
targetCompatibility = 1.8

def createSymlinks(archivePath, symlinkLocation) {
    exec {
        commandLine 'ln', '-fs', archivePath, symlinkLocation
        ignoreExitValue = false
    }
}

// Suffix is what will be added to the symlink
def createGatkSymlinks(destinationDir, archivePath, suffix, baseJarName, secondaryBaseJarName) {
    def finalSuffix = (suffix == "") ? "" : ("-" + suffix)

    def symlinkLocation = destinationDir.toString() + "/" + baseJarName + finalSuffix + ".jar"
    def symlinkLocation2 = destinationDir.toString() + "/" + secondaryBaseJarName + finalSuffix + ".jar"

    createSymlinks(archivePath.getAbsolutePath(), symlinkLocation)
    createSymlinks(archivePath.getAbsolutePath(), symlinkLocation2)
}

final isRelease = Boolean.getBoolean("release")
version = (isRelease ? gitVersion() : gitVersion() + "-SNAPSHOT").replaceAll(".dirty", "")

logger.info("build for version:" + version)
group = 'org.broadinstitute'

tasks.withType(Jar) {
    manifest {
        attributes 'Implementation-Title': 'Quartet IBD Analysis tools',
                'Implementation-Version': version,
                'Main-Class': project.mainClassName,
                'GATK-Version': gatkVersion,
                'Picard-Version': picardVersion,
                'htsjdk-Version': htsjdkVersion
    }
}

wrapper {
    gradleVersion = '3.1'
}

tasks.withType(ShadowJar) {
    from(project.sourceSets.main.output)
    baseName = project.name + '-package'
    mergeServiceFiles()
    relocate 'com.google.common', 'org.broadinstitute.hellbender.relocated.com.google.common'
    zip64 true
    exclude 'log4j.properties' // from adam jar as it clashes with hellbender's log4j2.xml
    exclude '**/*.SF' // these are Manifest signature files and
    exclude '**/*.RSA' // keys which may accidentally be imported from other signed projects and then fail at runtime

    // Suggested by the akka devs to make sure that we do not get the spark configuration error.
    // http://doc.akka.io/docs/akka/snapshot/general/configuration.html#When_using_JarJar__OneJar__Assembly_or_any_jar-bundler
    transform(com.github.jengelman.gradle.plugins.shadow.transformers.AppendingTransformer) {
        resource = 'reference.conf'
    }
}

apply from: "testsettings.gradle"

shadowJar {
    configurations = [project.configurations.runtime]
    classifier = 'local'
    mergeServiceFiles('reference.conf')
    doLast {
        // Create a symlink to the newly created jar.  The name will be gatk.jar and
        //  it will be at the same level as the newly created jar.  (overwriting symlink, if it exists)
        // Please note that this will cause failures in Windows, which does not support symlinks.
        createGatkSymlinks(destinationDir.toString(), archivePath, "", baseJarName, secondaryBaseJarName)
    }
}

task localJar{ dependsOn shadowJar }

// A jar that only contains the test classes and resources (to be extracted for testing)
task shadowTestClassJar(type: ShadowJar){
    group = "Shadow"
    from sourceSets.test.output
    description = "Create a jar that packages the compiled test classes"
    classifier = "test"
}

// A minimal jar that only contains the extra dependencies needed for running the tests
task shadowTestJar(type: ShadowJar){
    group = "Shadow"
    description = " A minimal jar that only contains the extra dependencies needed for running the tests that arent packaged in the main shadow jar"
    from {
        (project.configurations.testRuntime - project.configurations.runtime ).collect {
            it.isDirectory() ? it : it.getName().endsWith(".jar") ? zipTree(it) : it
        }
    }
    classifier = "testDependencies"
}


task javadocJar(type: Jar, dependsOn: javadoc) {
    classifier = 'javadoc'
    from "$docBuildDir/javadoc"
}

task sourcesJar(type: Jar) {
    from sourceSets.main.allSource
    classifier = 'sources'
}

task testUtilsJar(type: Jar){
    baseName = "$project.name-test-utils"
    from sourceSets.testUtils.output
}

tasks.withType(Javadoc) {
    // do this for all javadoc tasks, including gatkDoc
    options.addStringOption('Xdoclint:none')
}

javadoc {
    // This is a hack to disable the java 8 default javadoc lint until we fix the html formatting
    // We only want to do this for the javadoc task, not gatkDoc
    options.addStringOption('Xdoclint:none', '-quiet')
    source = sourceSets.main.allJava + files(configurations.externalSourceConfiguration.collect { zipTree(it) })
    include '**/*.java'
}


task testUtilsJavadoc(type: Javadoc) {
    // This is a hack to disable the java 8 default javadoc lint until we fix the html formatting
    // We only want to do this for the javadoc task, not gatkDoc
    options.addStringOption('Xdoclint:none', '-quiet')
    source = sourceSets.testUtils.allJava
    classpath = sourceSets.testUtils.runtimeClasspath
    destinationDir = file("$docBuildDir/testUtilsJavadoc")
    include '**/*.java'
}

task testUtilsJavadocJar(type: Jar, dependsOn: testUtilsJavadoc){
    baseName = "$project.name-test-utils"
    classifier = 'javadoc'
    from "$docBuildDir/testUtilsJavadoc"
}

task testUtilsSourcesJar(type: Jar){
    baseName = "$project.name-test-utils"
    classifier = 'sources'
    from sourceSets.testUtils.allSource
}

defaultTasks 'bundle'
